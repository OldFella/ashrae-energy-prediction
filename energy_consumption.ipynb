{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "YJ7GB-en64c5",
    "outputId": "df537d52-4951-4afc-af0a-743723c32370"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oFwm0xrg59vN",
    "outputId": "2c26d963-5cb9-4cac-dba8-397015df4fca"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "mpl.rcParams['axes.grid'] = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUIZXXVm7HSI"
   },
   "outputs": [],
   "source": [
    "# load data located ashrae_data into dataframes \n",
    "train_csv_path = '/content/drive/My Drive/ashrae_data/train.csv'\n",
    "weather_train_csv_path = '/content/drive/My Drive/ashrae_data/weather_train.csv'\n",
    "test_csv_path = '/content/drive/My Drive/ashrae_data/test.csv'\n",
    "building_metadata_csv_path = '/content/drive/My Drive/ashrae_data/building_metadata.csv' \n",
    "primary_usage_translations_csv_path = '/content/drive/My Drive/ashrae_data/primary_usage_translations.csv' \n",
    "\n",
    "train_df = pd.read_csv(train_csv_path) \n",
    "weather_train_df = pd.read_csv(weather_train_csv_path) \n",
    "building_metadata_df = pd.read_csv(building_metadata_csv_path) \n",
    "primary_usage_translations_df = pd.read_csv(primary_usage_translations_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzcoEq0R11rz"
   },
   "source": [
    "## Visualizing a sample\n",
    "To get a feel for the data, let's have a look at a few example meter readings from a random building.\n",
    "We pick a sample of size 120 to get energy consumptions for a five day timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 818
    },
    "colab_type": "code",
    "id": "-P_dZEc31F0W",
    "outputId": "d6f4f461-61cb-40e3-d7bd-58e956286890"
   },
   "outputs": [],
   "source": [
    "# get random variables that will be used to collect the data...\n",
    "sample_building_ids = [np.random.randint(200,300) for i in range(4)]\n",
    "sample_starts = [np.random.randint(0,1000) for i in range(4)]\n",
    "\n",
    "\n",
    "# collect samples\n",
    "sample1 = train_df.meter_reading.loc[train_df.building_id == sample_building_ids[0]].loc[train_df.meter == 0][sample_starts[0]:sample_starts[0] + 120]\n",
    "sample2 = train_df.meter_reading.loc[train_df.building_id == sample_building_ids[1]].loc[train_df.meter == 0][sample_starts[1]:sample_starts[1] + 120]\n",
    "sample3 = train_df.meter_reading.loc[train_df.building_id == sample_building_ids[2]].loc[train_df.meter == 1][sample_starts[2]:sample_starts[2] + 120]\n",
    "sample4 = train_df.meter_reading.loc[train_df.building_id == sample_building_ids[3]].loc[train_df.meter == 1][sample_starts[3]:sample_starts[3] + 120]\n",
    "\n",
    "\n",
    "# init figure\n",
    "fig, axes = plt.subplots(nrows=2,ncols=2,figsize=(12,6))\n",
    "# plot the samples\n",
    "sample1.plot(ax = axes[0][0],subplots=True, linestyle = (0, (1,1)), color = 'purple')\n",
    "sample2.plot(ax = axes[0][1],subplots=True, linestyle = (0, (1,1)), color = 'purple')\n",
    "sample3.plot(ax = axes[1][0],subplots=True, linestyle = (0, (1,1)), color = 'purple')\n",
    "sample4.plot(ax = axes[1][1],subplots=True, linestyle = (0, (1,1)), color = 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzyfbWrY_Ofa"
   },
   "outputs": [],
   "source": [
    "def convert_timestamp(timestamp):\n",
    "    return int(timestamp[5:14].replace(' ','').replace('-','').replace(':',''))\n",
    "\n",
    "\n",
    "def get_sample(building_id, meter, start, size, split):\n",
    "    \"\"\"\n",
    "    data:\n",
    "                    site    building_id     meter   meter_reading   air_temp    cloud_coverage  wind_speed  wind_direction  ...\n",
    "    time start\n",
    "    time start+1\n",
    "    ...\n",
    "    time split\n",
    "\n",
    "    labels:\n",
    "                    meter_reading\n",
    "    time split+1\n",
    "    time split+2\n",
    "    ....\n",
    "    time start+size\n",
    "    \"\"\"\n",
    "    site_id = building_metadata_df['site_id'].loc[building_metadata_df['building_id']==building_id].values[0] # get site_id of building\n",
    "\n",
    "    # get train and weather data in relevant time window\n",
    "    t = train_df[['timestamp', 'meter_reading']].loc[train_df['building_id']==building_id].loc[train_df['meter'] == meter][start:start+size] #?\n",
    "    w = weather_train_df[['timestamp','air_temperature','cloud_coverage','precip_depth_1_hr','wind_speed']].loc[weather_train_df['site_id']==site_id][start:start+size] # TRY maybe remove timestamp to avoid merge problems\n",
    "    t.set_index('timestamp')\n",
    "    w.set_index('timestamp')\n",
    "\n",
    "    sample_merged = pd.merge(t, w, on=['timestamp']) # merge the two\n",
    "    sample_merged.timestamp = sample_merged.timestamp.apply(convert_timestamp) # make timestamp numeric\n",
    "    sample_merged = (sample_merged - sample_merged.mean()) / sample_merged.std() # standardize the data\n",
    "    sample_merged = sample_merged.fillna(0) # replace nan values with zeros\n",
    "    sample_merged['site_id'] = [site_id for x in range(sample_merged.shape[0])] # add site_id as column\n",
    "    sample_merged['building_id'] = [building_id for x in range(sample_merged.shape[0])]\n",
    "    sample_merged['meter'] = [meter for x in range(sample_merged.shape[0])]\n",
    "\n",
    "\n",
    "    data = sample_merged[:split] # split into data...\n",
    "    labels = sample_merged['meter_reading'][split:] # ...aaand labels\n",
    "\n",
    "    # print(data.shape)\n",
    "    # print(labels.shape)\n",
    "    return data.to_numpy(), labels.to_numpy()#, sample_merged # return as numpy array\n",
    "\n",
    "\n",
    "def pick_samples(num_buildings = 1, start_range = (0,10), offset = 0):\n",
    "    \"\"\" Use get_sample to build a training data set. \"\"\"\n",
    "    all_data, all_labels = [],[]\n",
    "    building_ids = train_df.building_id.unique()\n",
    "    c = 0\n",
    "    for id in building_ids[offset:offset+num_buildings]:\n",
    "        for start in range(start_range[0], start_range[1], 10):\n",
    "            for meter in [0,1]: #just try 1\n",
    "                c += 1\n",
    "                data, labels = get_sample(id, meter, start, 5*24,4*24)\n",
    "                all_data.append(data)\n",
    "                all_labels.append(labels)\n",
    "                if c%500 == 0:\n",
    "                    print(\"sample {} of {}...\".format(c, num_buildings * 2 * ((start_range[1]-start_range[0]) / 10)))\n",
    "\n",
    "    return all_data, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "7PFSqUZE5RlL",
    "outputId": "fc7391e9-82b4-4784-b848-c400ef107ebe"
   },
   "outputs": [],
   "source": [
    "display(dfs[np.random.randint(0,49)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "r2M0OaAib954",
    "outputId": "f1420d75-22fd-4233-d999-f41a91e17b96"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = pick_samples(50, start_range = (0,1000), offset=200)\n",
    "x_val, y_val = pick_samples(10, start_range= (0,1000), offset = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U49RinIN9FR9"
   },
   "source": [
    "## Cleaning the Data\n",
    "Sometimes there aren't 24 values for a label, so we need to remove those rows. This way we will avoid problems down below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "NzEeTSh8wPfk",
    "outputId": "a3a47121-b5df-45b2-bef6-c3b1cd6ca7f7"
   },
   "outputs": [],
   "source": [
    "def remove_broken_samples(data, labels, output_shape = 24):\n",
    "    \"\"\" Removes samples where output dimension doesn't match the required size. \"\"\"\n",
    "    clean_data, clean_labels = [], []\n",
    "    broken_sample_count = 0\n",
    "    working_sample_count = 0\n",
    "    for i, label in enumerate(labels):\n",
    "        if label.shape[0] == output_shape:\n",
    "            clean_data.append(data[i])\n",
    "            clean_labels.append(labels[i])\n",
    "            working_sample_count += 1\n",
    "        else:\n",
    "            broken_sample_count += 1\n",
    "    \n",
    "    print(\"Removed {} samples... {} remaining.\".format(broken_sample_count, working_sample_count))\n",
    "    \n",
    "    return clean_data, clean_labels\n",
    "\n",
    "\n",
    "\n",
    "x_train,y_train = remove_broken_samples(x_train, y_train)\n",
    "x_val,y_val = remove_broken_samples(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IszRWy6Ww6uJ"
   },
   "source": [
    "## Store the training data\n",
    "To avoid sampling the data all over again each time we store it in a pickle file. This will allow us to load it much faster the next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGzNWlI0w5xp"
   },
   "outputs": [],
   "source": [
    "# !ls drive/My\\ Drive/ashrae_data\n",
    "\n",
    "def pickle_data(filename, data):\n",
    "    with open('/content/drive/My Drive/ashrae_data/' + filename, 'wb') as f:\n",
    "        pickle.dump(data,f)\n",
    "\n",
    "\n",
    "pickle_data('train_samples_x.pkl', x_train)\n",
    "pickle_data('train_samples_y.pkl', y_train)\n",
    "pickle_data('val_samples_x.pkl', x_val)\n",
    "pickle_data('val_samples_y.pkl', y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlcQwJ13yuxf"
   },
   "source": [
    "## Load the pickled data\n",
    "Let's load the data from the pickle files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ABvvAyZy2YF"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/ashrae_data/' + 'train_samples_x.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "\n",
    "with open('/content/drive/My Drive/ashrae_data/' + 'train_samples_y.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('/content/drive/My Drive/ashrae_data/' + 'val_samples_x.pkl', 'rb') as f:\n",
    "    x_val = pickle.load(f)\n",
    "\n",
    "with open('/content/drive/My Drive/ashrae_data/' + 'val_samples_y.pkl', 'rb') as f:\n",
    "    y_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "S9ORlVFxvpyO",
    "outputId": "44f6944e-8456-446b-bfae-f8208d7a0a4a"
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFkrYLT6V-H_"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "val_data = val_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k39NF2xhXmsW"
   },
   "source": [
    "## Defining the Model\n",
    "After collecting and preparing all the data we create a model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lQ1sGR1qXxub",
    "outputId": "7432bb17-c47f-440e-dc99-fde66a567b76"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(\n",
    "    32,\n",
    "    return_sequences = True,\n",
    "    input_shape=(x_train[0].shape)\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)))\n",
    "model.add(tf.keras.layers.Dense(24))\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0),loss='mae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "ljIjHzsDcyEs",
    "outputId": "095f453e-ae6b-414c-fa7f-a90e908673ec"
   },
   "outputs": [],
   "source": [
    "class AshraeModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(AshraeModel, self).__init__()\n",
    "\n",
    "        self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(96,9))) # was 32\n",
    "        self.lstm2 = tf.keras.layers.LSTM(128,return_sequences=True)\n",
    "        self.bi_lsmt = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation = 'tanh')) # is much faster than relu and performs similarly\n",
    "        self.out = tf.keras.layers.Dense(24)\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        query_value_attention_seq = tf.keras.layers.Attention()([inputs, inputs])\n",
    "        query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(query_value_attention_seq)\n",
    "        query_encoding = tf.keras.layers.GlobalAveragePooling1D()(inputs)\n",
    "\n",
    "        input_layer = tf.keras.layers.Concatenate()([inputs, query_value_attention_seq])\n",
    "\n",
    "        x = self.lstm1(input_layer)\n",
    "        x = tf.nn.dropout(x, 0.2)\n",
    "        x = self.lstm2(x)\n",
    "        x = tf.nn.dropout(x, 0.2)\n",
    "        x = self.bi_lsmt(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model2 = AshraeModel()\n",
    "model2.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0),loss='mae')\n",
    "model2.build((8,96,9))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "D5Cicy7EddUI",
    "outputId": "60db851b-9ae8-4f0b-d28a-47b546c074bc"
   },
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 100\n",
    "EPOCHS = 500\n",
    "\n",
    "\n",
    "history = model2.fit(train_data, epochs=EPOCHS,\n",
    "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                          validation_data=val_data,\n",
    "                                          validation_steps=50\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6lNeKHUmdM8U",
    "outputId": "a064f533-ffb2-42cd-9df0-9b1fe346e2f7"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (16, 4)\n",
    "\n",
    "\n",
    "# make prediction after training\n",
    "for x, y in val_data.take(4):\n",
    "    # each is mini batch of size 8\n",
    "    r = np.random.randint(0, BATCH_SIZE-1)\n",
    "    meter = int(x[r][2][8])\n",
    "    print(meter)\n",
    "    meter_readings_x = [i[1] for i in x[r]] # pick random sample from mini batch\n",
    "    prediction = model2.predict(x)[r]\n",
    "\n",
    "\n",
    "    plt.plot([x for x in range(96)], meter_readings_x, color = 'darkslateblue')\n",
    "    plt.plot([x for x in range(96, 120)],y[r], color = 'darkslateblue')#, linestyle = 'dashed')\n",
    "    plt.plot([x for x in range(96, 120)], prediction, linestyle = 'dashed', color = 'darkorange')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "7Ogg808PfMZI",
    "outputId": "629f865a-d3bb-4ebc-8241-bc8f90b6ba07"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "working_energy_consumption.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
